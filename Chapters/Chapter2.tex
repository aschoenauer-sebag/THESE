%\newcommand{\tw}[1]{\textcolor{red}{\bf [TW:~#1]}}

\lhead{Chapter 2 - \emph{A generic methodological framework for studying single cell motility}} % Set the left side page header to "List of Figures"
\chapter{A generic methodological framework for studying single cell motility}
This chapter was published in~\cite{motiw}.
\section{Studying single cell motility in a HT setup}
% Introduction: cell motility

Cell \textit{migration} describes "any directed cell movement within the body", as according to~\cite{pmid22940039}. On the other hand, cell \textit{motility} more broadly encompasses any cell movement which is active, i.e. energy-consuming. Cell motility plays a key role in many physiological processes including embryonic development or immune response~\cite{pmid18711433}, and is also involved in pathological processes such as fibrosis and metastasis. The latter is dependent on the ability of cancer cells to migrate, both as single cells and collectively~\cite{pmid16888756},~\cite{pmid20460404}, which highlights the need to understand the molecular basis of both processes.
%\textcolor{blue}{Also say something about cell motility at different time scales?}

% Assays for cell motility
\paragraph{Cell motility assays}
Many \textit{in vitro} assays have been specifically designed to study cell motility~\cite{pmid16888756},~\cite{pmid22940039}. The most classic methods are wound healing assay, cell exclusion zone assay, and trans-well migration assay. They measure the ability of cells to migrate into some free space (the wound, the exclusion zone) or a new chamber, in a limited amount of time. These assays have the advantage of being widely known; as an example, the Boyden assay is a trans-well migration assay which was introduced in 1962~\cite{pmid13872176}. More recently, particle-coated plates were developed, in which particles are phagocyted by cells as they move~\cite{pmid329998}.
In this assay, a single picture is taken at the end of the experiment,
showing the path that was cleared by the moving cell. Analysis of
these images is therefore equivalent to the analysis of the temporal
projection of single cell trajectories.  
% The analysis of cell imprint is equivalent to that of its trajectory. 
%This method was recently adapted to be used in a HT setup~\cite{pmid18213366}. STUDY ONLY ON 55 GENES

\paragraph*{}
Live-imaging data can be obtained from experiments using any of these methods (except the trans-well migration assay in its classical version). Data at single cell level could therefore theoretically be obtained. But the classic assays are most of the time used as endpoint assays: the experimenter is focused on getting aggregated data at the level of the cell population (e.g. wound closure time or percentage of cells staying in the upper compartment of the well).

However, single cell characteristics are relevant: they enable to detect patterns which are not visible at the population level, such as the existence of cell subpopulations with regard to their motility behaviours~\cite{pmid24324630},~\cite{pmid25129619},~\cite{pmid25799384},~\cite{motiw}. This finds an application in drug design, as one might want to target specific populations~\cite{pmid15539606},~\cite{pmid20461076}. The little use of single cell motility assays is probably due to both cultural and technical reasons: people are used to proceeding at population level, and univariate analysis is easier than multivariate analysis. Furthermore, single cell motility studies in live cell imaging data have so far been limited to low-to-medium throughput~\cite{pmid21423205},~\cite{pmid25799384}. While this limitation has in principle be alleviated recently~\cite{pmid20360735}, live cell imaging still remains a relatively expensive technique and produces large amounts of data, thus requiring an appropriate infrastructure, both for imaging and IT. 
%On top of the technical and cultural reasons which were mentioned supra, a third bottleneck can be added: acquiring large-scale data is expensive. 
% Neumann ~\cite{pmid20360735}

\paragraph*{HT motility studies}
As a consequence, there are only few automatic workflows for the comprehensive analysis of single cell trajectories including tracking, statistical analysis and data mining, applicable to HCS data: ~\cite{pmid25774502} analyses temporal projections of single cell trajectories, as observed by cell imprints (see above). Information on membrane dynamics is indirectly inferred from these data, but the data is not informative about direct movement features, such as instantaneous speed, curvature or, more importantly, resting time and speed variations. The methods published in \cite{pmid24324630} are based on manual tracking and do therefore not scale easily to HCS. 

%very little completely automatic workflow, from tracking to statistical analysis, were developed for the analysis of single cell trajectories in 2 dimensions: only ours and~\cite{pmid25774502} could be found\footnote{\cite{pmid24324630} is based on manual tracking.}. The latter approach works on cell imprints as described earlier. It enables them to study membrane dynamics which are recorded in cell imprints; however they do not get any detailed temporal information such as speed, curvature, or more importantly resting time and speed variations.

In this chapter, we present MotIW (\textbf{Mot}ility study \textbf{I}ntegrated \textbf{W}orkflow). A generic methodological framework, MotIW enables to quantitatively study cell motility at single cell resolution in HT time-lapse data in an unsupervised way. It consists of cell tracking, cell trajectory mapping to an original feature space, and outlier experiment detection according to a new statistical procedure (cf figure~\ref{workflow}). We show the power of our method in section~\ref{sec:simulation} by applying MotIW to simulated data, which allows us to estimate recall and precision to be expected on real data. We then apply this workflow to a previously published genome-wide screen by RNA interference (RNAi) and live cell imaging, the Mitocheck dataset, in section~\ref{sec:mitocheck} of chapter~\ref{chap:reuse}.

\begin{figure*}[ht]
\centerline{\includegraphics[scale=0.3]{figures/Walter_295_fig_1.png}}
\caption{Overview of MotIW}
\label{workflow}
\end{figure*}  

\section{MotIW overview}
\label{sec:workflow}
In this section, we present MotIW, our workflow for the automatic and
quantitative analysis of single cell motility in video sets from
time-lapse microscopy-based screens. Figure~\ref{workflow} summarizes
its different steps. 
Briefly, for each video nuclei are segmented and features are
extracted as published previously \cite{Walter2010},\cite{cellcognition}. Cells are tracked using a
machine-learning based tracking procedure, described in
section~\ref{sec:celltracking}. The trajectories are then mapped to a
feature space described in section~\ref{sec:features}. Presented in
section~\ref{sec:stats}, an original statistical procedure then
enables the detection of experiments in which single cell motility is
significantly different than that in control movies. Finally,
section~\ref{sec:simulation} describes the simulation of trajectories
which allows us to validate the performance of the workflow.

%\subsection{Object segmentation}
\subsection{Segmentation and tracking}
\label{sec:motiw_seg}
\label{sec:celltracking}

%
The first step of the workflow is the establishment of single cell
trajectories: we want to follow individual cells over time and record
their spatial displacements. Many methods have been proposed in the
image analysis and computer vision communities for the automatic
tracking of individual objects. When it comes to the tracking of
biological objects, such as cells or particles (e.g.
single molecules or vesicles), there are two main approaches. On the one hand, it is possible to associate pre-segmented objects in consecutive frames, e.g. ~\cite{lou},
~\cite{citeulike:11229467}, ~\cite{Chenouard2014}.% the object-association approach associates
pre-segmented objects in consecutive frames. On the other hand, the deformable model approach relies on identifying and modeling objects in the first frame, and linking them to objects in consecutive frames by updating the models, e.g. \cite{pmid12585703}. Methods also differ in the amount of prior knowledge which is hard-coded in the tracking model. For example,~\cite{pmid18656418} assumes that there are three types of
cell motion: Brownian motion, migration at a constant speed, and
migration at a constant acceleration. At the other
extreme,~\cite{pmid16043363} formulates tracking as an optimization
problem, where a cost function of particle matches, typically depending on distance and
intensity moments, is minimized.  
In particular, no constraint - except for maximal speed - on
the type of movement is imposed. 

We chose to keep segmentation and tracking steps independent: objects are identified before the establishment of object temporal correspondences by our tracking model. While the deformable model approach is in principle appealing as it jointly solves segmentation and tracking, it relies on a high time resolution and is therefore less generally applicable. Furthermore, as segmentation and tracking are not independent in this approach,
the resulting method is necessarily less modular.  

% Segmentation
\paragraph*{Segmentation}
Segmentation of nuclei is in principle a relatively simple problem, as
nuclei appear as bright objects on a dark background. The
main difficulty arises when two or more nuclei come in close proximity
to each other and are therefore segmented as one single object. Classically,
this problem is solved by splitting objects after the first
segmentation, e.g. \cite{cellcognition}. 
Briefly, a distance map of the binary segmentation is
calculated, where we assign to each pixel its distance to the closest
background pixel. If objects are touching, this typically generates
important concavities in the resulting binary shape, thereby producing
prominent maxima in the distance map. The final split is generated by
calculating the Watershed transformation on the inverted distance
map. To avoid false splits, the distance map is typically preprocessed
by either morphological or linear filtering. The problem of this
strategy is that non-convex shapes may be also split, and consequently
the detection of multi-nucleated morphologies will be more
difficult \cite{Walter2010}. Nevertheless, we chose to start from this segmentation
strategy, as implemented in CellCognition, as the main purpose of this
study is to track nuclei and to analyze spatial trajectories, which
will be eased by splitting the nuclei. 

%\subsection{Cell tracking}
%\label{sec:celltracking}
%\paragraph{mettre ou pas ?}
%There are two main parameters governing the design of a cell tracking
%algorithm. The first parameter is discrete and linked to the algorithm
%input. The deformable model approach is based on the images
%themselves. It relies on identifying and modeling objects on the first
%frame, and linking them to objects in consecutive frame by updating
%the models, e.g. \cite{pmid12585703}. On the other hand, the object
%association approach associates pre-segmented objects in consecutive
%frames, e.g. \cite{lou}.   

%The second parameter is continuous and describes how much prior knowledge is hard-coded in the tracking model. For example,~\cite{pmid18656418} assumes that there are three types of cell motion: Brownian motion, migration at a constant speed, and migration at a constant acceleration. At the other extreme,~\cite{pmid16043363} defines a cost function which particle matching should minimize, which is based on distance and intensity moments.
%We are willing to apply the current workflow to multiple screens. Since specific biological data may demand specific segmentation algorithms, the second approach was chosen. Indeed, it enables the workflow to remain as modular as possible.

\paragraph*{Cell tracking by supervised learning}
Cell tracking should be able to face several challenges which are
common in videos from high content screens. They
include high population density in each picture, high phenotypic
inter-cell variability, and possibly low time resolution between
successive images. Furthermore, the algorithm has to handle
apparitions, disparitions, divisions and fusions. Cells can indeed disappear, e.g. when they move outside the field of view or lose adhesion. They can also appear, for instance if they enter the field of view or more rarely if the expression of their fluorescent marker increases. Finally, they can fuse or seem to fuse, for example when a nucleus moves on top of another, or if two nuclei are still connected by chromosome bridges. %Fusions correspond to touching nuclei which were not correctly split by the segmentation algorithm, nuclei moving on top of each other, or segregation problems, where nuclei seem to be separated but are in reality still connected by chromosome bridges, which becomes apparent a few timepoints later when the nuclear envelope has reformed. 
%This latter event results from occlusion or segmentation errors; it can also be observed following the formation of chromosome bridges.
%Different data sets usually require different segmentation algorithms. For sake of modularity, we therefore prefer to keep
%segmentation and tracking steps independent. 

To be applicable in a screening context, we cannot \textit{a priori}
model cell motion, as such hypotheses are bound to break in the
presence of phenotypes. Indeed, the impact of chemical exposure on
cell motion is not known. As we also wished to avoid any manual parameter tuning, we extended a non-parametric structured learning approach from~\cite{lou}. %Briefly, tracking cells in two consecutive frames can be seen as a bi-partite graph matching problem:
%two sets of nodes have to be connected. Each node is
%characterized by a set of features, allowing for the definition of a
%cost function for linking two nodes. The solution can therefore by
%found by finding the node association with minimal cost under the
%constraint that all nodes have been appropriately considered. 
%The information which will be learned from
%a set of user-annotated cell associations is the relative importance
%of node features in determining the right matching. 

We first characterize each cell nucleus in each image by a set of 239 shape and texture features on the one hand (~\cite{Walter2010}, ~\cite{cellcognition}), and geometric features on the other hand (its distance to the border, its position in the image, and the orientation of its main axis). The goal of cell tracking in this approach is to match cells in successive images, by assigning them the most likely instant temporal behaviour in the set $\mathbf{E}$ = \{\textit{move},~\textit{appear},~\textit{disappear},~\textit{split in 2 or 3},~\textit{merge at 2 or 3}\}. %The relative importance of match features for cell matching is the information which will be learned. 
All possible matches between cells in consecutive frames are exhaustively considered, subject to
distance thresholding. Match features are: 
\begin{itemize}
\item the absolute difference of shape and texture features if the event is \textit{move}, \textit{split}, \textit{merge}, the object features otherwise
\item the geometrical distance between object at time $t$, $Obj_{i, t}$ and object at time $t+1$, $Obj_{j, t+1}$, if the event is \textit{move}, \textit{split}, \textit{merge}, the minimal distance to the image border otherwise,
\item the angle between $Obj_{i, t}$ and the elements of $Obj_{j, t+1}$, if the event is a \textit{split} (angle $\alpha$ on fig.~\ref{fig:angles}),
\item the angle between the main axis of $Obj_{i, t}$ and $Obj_{j, t+1}$ weighted by their average eccentricity, if the event is a \textit{move} (angle $\beta$ on fig.~\ref{fig:angles}).
\end{itemize}

\begin{figure}[ht]
\centerline{\includegraphics[scale=0.27]{figures/angles_description.png}}
\caption{Illustration of angular match features.}
\label{fig:angles}
\end{figure}


%The optimal matching is defined as the one that maximizes a likelihood function, which depends on match features and on weights for each feature:
The optimal object matching $\widehat{z}(t)$ comes down to bi-partite graph matching: it is solved by maximizing a likelihood function $L$ which depends on the weights $w$ of match features and the match features $f^e_{i, j}$, subject to the constraint that all objects are matched in both frames (cf equation~\ref{formulation}).
%\begin{equation}
%\widehat{z}(t) = \argmax_{\substack{z(t)}}~ \mathbf{L}(z(t) ; w) 
%\label{formulation}
%\end{equation}
%where 
%\begin{align*}
%\mathbf{L}(z(t) ; w) & = \sum_{\substack{e\in \mathbf{E}\\Obj_{i, t}\\Obj_{j, t+1}}} <w^e, f^e_{i, j}> z^{e}_{i, j}(t)\\
% & s.t.\ \ \forall i \sum_{\substack{e\\Obj_{j, t+1}}} z^{e}_{i, j}(t) = 1\ \\ 
% & and\ \ \forall j \sum_{\substack{e\\Obj_{i, t}}} z^{e}_{i, j}(t) = 1
%\end{align*}

\begin{align}
\widehat{z}(t) & = \argmax_{\substack{z(t)}}~ \mathbf{L}(z(t) ; w) \\
 & s.t.\ \ \forall i \sum_{\substack{e\\Obj_{j, t+1}}} z^{e}_{i, j}(t) = 1\ \\ 
 & and\ \ \forall j \sum_{\substack{e\\Obj_{i, t}}} z^{e}_{i, j}(t) = 1
\label{formulation}
\end{align}
where 
\begin{equation*}
\mathbf{L}(z(t) ; w) = \sum_{\substack{e\in \mathbf{E}\\Obj_{i, t}\\Obj_{j, t+1}}} <w^e, f^e_{i, j}> z^{e}_{i, j}(t)\\
\end{equation*}

The weights $w$ are learned by a structured support vector machine using annotated trajectories, following the formulation of~\cite{lou} (drawing on~\cite{Tsochantaridis}). The likelihood maximization, an integer linear programming (ILP) problem, is solved by IBM Cplex.
% This results in a bi-partite graph matching problem; it is solved by an integer linear program. The weights are learned by a support vector machine using annotated trajectories, following the formulation of~\cite{lou}.

The extension compared to~\cite{lou} lies in the choice of match
features. Furthermore, we enabled the tracking model to learn from
partial annotations of different experiments\footnote{However, this is
  not learning from partial annotations in the sense
  of~\cite{loupartial}. Indeed, in our implementation of~\cite{lou},
  the user chooses a subset of cells which has to be annotated on all
  movie frames. In~\cite{loupartial}, the user can choose both a
  subset of movie frames and a subset of cells (s)he wishes to
  annotate on those frames.}. This permits the user to integrate
examples from both control and non-control experiments in the training
set, which is crucial to guarantee that the model can efficiently
track cells in all conditions. We also added three object division and
fusion to $\mathbf{E}$. This is important in a screening context,
where aberrant cell divisions may occur. We also implemented a more time-efficient computation of match hypotheses
using kd-trees.

\paragraph*{}
To validate MotIW's cell tracking procedure, we compare it to Cell Cognition's constrained nearest-neighbour (CNN) tracking algorithm, and to~\cite{jaqaman} as implemented in Cell Profiler \cite{Carpenter2006}. We have chosen these two approaches for benchmarking, as they are available in popular High Content Screening software. \cite{jaqaman} views tracking as a linear assignment problem (LAP). It starts by computing 1-to-1 matches in consecutive frames, which produces tracklets. It then connects these tracklets by solving an optimization problem which is global both in time and space (2D-space and time duration of the experiment). For performing this optimization, that is, for choosing when to perform tracklet merges, splits, appearances and disappearances, it uses user-defined costs. 

Our training set consists of approximately 32,000 matches, among which
0.5\% \textit{appear}, 0.5\% \textit{disappear}, 1\% \textit{merge}
and 2\% \textit{split}. Data was taken from the Mitocheck data
set, and in particular from both control experiments \textbf{and}
experiments as selected by~\cite{pmid20360735} for being significantly
different from controls regarding nuclear morphology. This ensures
that the algorithm also works in the presence of phenotypes. One may
nevertheless be willing to perform cell tracking before having
performed any statistical analysis. In this case, learning from
control experiments only slightly diminishes the cell tracker
performances, albeit non significantly. 

To establish the data set, we first performed tracking with
CellCognition's CNN tracking and manually corrected for mistakes made
by the algorithm. As in most cases, even such a simple tracker is able
to find the correct assignment, we found this procedure much less time
consuming than annotating all correspondences from scratch. 
As shown in Table~\ref{accuracy}, MotIW outperforms the other two
methods as measured by the average accuracy on the five movement
types. Note that these are not the overall accuracies of correct
assignments, which are much higher for all three methods. 
As can be seen on fig.~\ref{details}, all three methods show similarly good
performances on \textit{move} events and have therefore similar
overall (pooled) accuracies. The contribution of the learning approach
is most important for the other events, such as cell division, when
object matching is less trivial. 

In particular, it is interesting to see that this method even outperforms
~\cite{jaqaman}, which relies on an optimization scheme in space and
time, i.e. optimizes not only the assignments between two consecutive
frames, but on the entire video sequence. While this might seem
surprising at first sight, it is explicable by the fact that the
latter approach was developed for particle tracking. Particles have only few distinguishing features, such as
intensity and size. It is therefore feasible to manually define and tune a cost function for particle tracking  based on these features only. It is nevertheless hardly feasible for larger feature sets, which are necessary to track more complex objects in terms of texture and shape. %In this case, similarity between objects becomes a more important parameter for finding the correct correspondences.

In the future, it will be interesting to see whether this result can
still be improved by an optimization scheme in time. Another promising
strategy for future investigation will be to couple segmentation
with tracking without relying on a deformable model approach. In
particular, we could argue that split algorithms can provide us with
alternative hypotheses on segmentation. The best combination of
segmentation and tracking can then be found by global optimization in
time. 

Altogether, we conclude that the tracking procedure is sufficiently
accurate to generate single cell trajectories. 

%Nevertheless, an optimization in time might still be applicable and
%still improve the tracking result. 


%In the latter case, it cannot be based on user-defined costs without
%considering any characteristics of the object as
%in~\cite{jaqaman}. 
%Indeed, the latter approach was developed for
%particle tracking, where one is not able to quantitatively describe,
%e.g., the object's mean intensity or area. Therefore, although
%the~\cite{jaqaman} approach performs an optimization which is global
%in time and space, using object quantitative characteristics and
%learning their importances on the data proves to be even more
%efficient for the final tracking accuracy. 

\begin{table}[!ht]
\centering
\caption{Mean recall and precision on all types of matches $\mathbf{E}$ (10-fold cross-validation)\label{accuracy}}{
\begin{tabular}{l|c|c}
Algorithm & Mean recall (\%) & Mean precision(\%)\\
\hline
CNN & 72.7 & 62.8 \\
\cite{jaqaman} & 78.3 & 73.0 \\
MotIW  & 91.1 & 91.5 \\
\end{tabular}}

\end{table}
\begin{figure}[ht]
\centerline{\includegraphics[scale=0.4]{figures/Walter_295_fig_2.png}}
\caption{Details of tracking precision and recall according to event types}
\label{details}
\end{figure}



\subsection{Trajectory features}
\label{sec:features}
Once cell tracking has been performed, each experiment is summarized
as a set of cell trajectories in the two-dimensional space over
time. Instead of analyzing these point sequences directly, we
calculate for each trajectory a set of relevant features which will allow us to
represent each trajectory to a point in this feature space. 
For instance, cell speed is an important characteristic of cell motion, and it
is certainly the most studied one. However, it makes sense to also
describe other aspects of movement. For instance, if we consider the example
trajectory of fig.~\ref{fig:01}, one might also be interested in
quantifying the percentage of time which is spent in each englobing
blue ball, or whether diffusion would have been an appropriate model
for this particular cell. A multivariate study of cell trajectories is
therefore relevant to capture all the information which they
contain. For this, a set of 15 features was assembled, partly from previous
publications on quantitative motility analysis, partly newly
designed. 

Robust and precise features are needed to account for the partial
stochasticity of cell migratory behaviour. We use three types of
features, as detailed in table~\ref{features}. 
\begin{figure}[!tpb]%figure1
\centerline{\includegraphics[scale=0.22]{figures/Walter_295_fig_3.png}}
\caption{A cell trajectory with notations}
\label{fig:01}
\end{figure}
\begin{table}[!h]
\centering
\caption{Cell trajectory features and their formulas. Notations: $(m_t)_{t=1\ldots T}$, time sequence of cell 2D positions. T, track time duration. P, total track length \label{features}}
{\begin{tabular}{ll}\hline
\multicolumn{2}{c}{Particle motion features}\\
\hline
Diffusion coefficient & According to~\cite{pmid16043363} \\
Diffusion adequation & Correlation between MSD(t) and $t$ \\
Movement type & According to~\cite{pmid16043363} \\
Englobing ball number & See text\\
Track entropy & See text \\
\hline
&\\
\multicolumn{2}{c}{Other global features}\\
\hline
Convex hull area & - \\
Effective path length & $L=\|m_{T}-m_1\|_2$ \\
Effective speed &  $L/\sqrt{T} $ \\
Largest move & - \\
Straightness index & $\sqrt{T} L/P $ \\
Track curvature & See text \\
\hline
&\\
\multicolumn{2}{c}{Averaged local features}\\
\hline
%\parbox{2.5cm}{\raggedright Mean persistence} &$\dfrac{1}{T-1}\sum \cos(\alpha_{t+1}-\alpha_{t})$\\
\parbox{2.5cm}{\raggedright Mean squared displacement (MSD)} & $\dfrac{1}{T-1}\sum \|m_{t}-m_{t-1}\|_2^2 $\\
\parbox{2.5cm}{\raggedright Mean signed turning angle} & $\arctan(\dfrac{\Sigma \sin(\alpha_{t+1}-\alpha_{t}) }{\Sigma \cos(\alpha_{t+1}-\alpha_{t}) }) $\\
\hline
\end{tabular}}{}
\end{table}

\paragraph{Particle motion features}~\\ This group of features
encompasses the diffusion coefficient and the movement type, which
were in the first place used to study particle motion
(see~\cite{ferrari},~\cite{pmid16043363} for one of its applications to single particle motion in Biology).  

Let us consider a particle, and note $m_t$ its position at timepoint $t$. The moment of
order $p$ of this particle, $<d^p>$, can be computed according to the following formula: 
\[
<d^p>= < \|m_{t}-m_{t-1}\|_2^p >_t
\]
%\textcolor{red}{\bf First, $<d^p>$ is an expectation, not a   sum. Either you write 1/N or E(). Second, it is not clear on what   you average. On particles or on different time points for the same   particle. I know that this is one weakness of these features, but   still you need to tell what you do.} 
For large $t$, it is proportionate to $t^{\gamma_p}$ for
most dispersive processes~\cite{ferrari}. Assuming that $\gamma_p$ is
proportionate to $p$ (i.e. that the particle movement is strongly
self-similar), the constant $\gamma = \gamma_p /p$ (hereafter the particle's
\textit{Movement type}) quantifies how directed the particle motion is. If
$\gamma$ is equal to $1$, the movement is perfectly directed, whereas
if $\gamma$ is equal to $0.5$, it is perfectly diffusive. Between
$0.5$ and $1$, the movement is super-diffusive, whereas below $0.5$ it
is called sub-diffusive.  

Furthermore, assuming $ \gamma = 0.5 $, the constant linking $<d^2>$ (that is, the mean squared displacement) and $t$ can be computed: it is the \textit{Diffusion coefficient}. The \textit{Diffusion adequation} is the correlation coefficient between $<d^2>$ and $t$, hence measuring how well the diffusive model applies to the track at hand.
\paragraph*{}
Here, we present two newly designed features to characterize the
alternance between periods of diffusive motion and periods of directed
motion: the track entropy and the englobing ball number. 

It has been observed that cell motion in 2D alternates between
diffusive and directed motions (in the absence of any perturbation or
chemical gradient). %REF\alcomment{can't really find any references at   the right time scale...} \twcomment{We can omit the citation}. 
The feature track \textit{Entropy} was designed to measure how the time
sequence of 2D cell positions $m_t=(x_t, y_t)$ distributes in balls of radius $r$. This will be computed greedily by recursively searching the center of a new ball of radius $r$ among the set of remaining track points, that will contain the biggest number of them. This
feature is calculated according to the following procedure, for each
track of time duration $T$: 
\begin{enumerate}
\item $S = \{1, \ldots, T\}$ 
\item while $S\neq\{\}$:\\
\ \ \ \ i. do $t^\star\leftarrow \argmax_S card(B_r(t))$ \\ \ where
$B_r(t) = \{ i \quad | \quad \|m_i-m_t\|_2 \leq r \,\,\, \mbox{and}$ \\
\indent $\quad \quad \quad \quad min{(\|m_{i-1}-m_t\|_2,\|m_{i+1}-m_t\|_2)} \leq r \}$ \\
%\ where $B_r(t) = \{ i | dist((x_i,y_i), (x_t, y_t)) \leq r, $
%\[dist((x_{i-1},y_{i-1}), (x_t, y_t)) \leq r\ \cup\ dist((x_{i+1},y_{i+1}), (x_t, y_t)) \leq r \} \]
ii. do $S \leftarrow S \backslash B_r(t^\star) $

\item Compute the track \textit{Entropy} according to the following formula:
\end{enumerate}
\begin{equation}
Entropy_r= -\dfrac{1}{T} \sum_{\substack{B_r}} \dfrac{card(B_{r})}{T} \log(\dfrac{card(B_{r})}{T})
\end{equation}

The track \textit{Entropy} measures the entropy of the distribution of track positions in balls of radius r. To deal with cells whose trajectories are concentrated in space, but were not concentrated in time, the constraint is imposed that these balls shall contain only consecutive positions in time. The englobing \textit{Ball number} is the number of balls of radius $r$ that contain all track positions. It is normalized by the square root of $T$ to be independent of the track time-length $T$.

Different radii may be relevant for different data (depending of,
e.g., the experiment time-lapse, the pixel size or the cell type). We
chose to use two different radii $r_1$ and $r_2$ with $r_1<r_2$, to
incorporate information about cell trajectories on two different
time-scales. $r_1$ and $r_2$ were manually chosen, such that for the Mitocheck data set, the corresponding features are neither constant over a large number of trajectories nor too correlated. They respectively correspond to approximately $2.5\mu m$ and $12\mu
m$. In the following, the features \textit{Entropy $i$} and 
\textit{Ball number $i$} correspond to radius $r_i$.  

%They correspond
                                %to approximately $2.5$ microm and
                                %$12$ microm on the Mitocheck
                                %dataset. 

\paragraph{Other global features}~\\
We further defined the following global descriptors of cell
trajectories: the cell's \textit{Largest move} along the trajectory, its track
\textit{Convex hull area} and its average \textit{Track
  curvature}. The track \textit{Convex hull area} is the area of the
convex hull containing all track points, as coloured in green on
fig.~\ref{convexhull}. It is normalized by the square root of the
track time-length. Following~\cite{pmid18213366}, this feature enables
us to have an idea of the area which the cell has visited during its
trajectory, although it does not exactly indicate the area which its
cytoplasm has covered. Finally, for each trajectory and each time-point $t$, an orthogonal regression is performed on $\{(x_i, y_i) | i \in \{t,\ldots, t+\Delta_t\} \}$ using orthogonal distance regression ($\Delta_t=10$). The mean \textit{Track curvature} of the trajectory is the average of all regression sums of squares. 
\paragraph{Averaged local features}~\\\\
Finally, two features are averaged local features, which are the cell
means squared displacement
(\textit{MSD}) and its \textit{Mean signed turning angle} (see table~\ref{features} for the formulae). 
\begin{figure*}[!ht]%figure1
\centerline{\includegraphics[scale=0.25]{figures/convex_hull.png}}
\caption{Convex hull of the example track from figure~\ref{fig:01}}
\label{convexhull}
\end{figure*}
\begin{figure*}[!tpb]%figure1
\centerline{\includegraphics[scale=0.45]{figures/Walter_295_fig_4.png}}
\caption{Heatmap showing trajectory feature similarities on a subset of the Mitocheck dataset (1.1 million trajectories coming from detected motility hit experiments according to MotIW). The dengrograms were obtained using the \textit{Ward} method and the euclidean distance between feature correlations.}\label{correlations}
\end{figure*}
\paragraph{Feature set evaluation}~\\
Track time-length is an irrelevant random variable for studying single cell motility, which could bias some features. Therefore, we ensured that they are not significantly correlated with this parameter: the correlation between track time-lengths and features is maximal for the \textit{Effective space length}, where it is equal to approximately $30\%$ (on a subset of the Mitocheck dataset, data not shown).
%\alcomment{leave next paragraph here or put it in results?? leave the plot ?? leave pca info to corroborate ?}
%\twcomment{True: it is a result of the analysis to the mitocheck
%  data. Nevertheless I think it can also stay here. Yes: we leave the
%  plot and the PCA.}

Figure~\ref{correlations} shows the correlation matrix for the
extracted features. 
%A heatmap shows feature similarities on figure~\ref{correlations}. It
%was obtained using the \textit{Ward} method on the euclidean distances
%between the feature correlations on a subset of the Mitocheck
%dataset. %It indicates that some features are highly correlated.  
One group of highly correlated features are visible in the bottom-left
corner of the heatmap, which encompasses speed-related features. The
existence of two feature subgroups within this group can be explained
by the following observation: the first group of features, from
\textit{Ball number 1} to \textit{MSD}, is linked to cell
instantaneous displacements, whereas the second group, from
\textit{Effective speed} to \textit{Entropy 2}, is linked to its
displacements on the whole trajectory.  

The other correlations can as well be explained by feature definitions. As an example, the anti-correlation between \textit{Mean signed turning angle} and \textit{Movement type} can be interpreted as follows: a low signed turning angle is indicative of correlated motion, which is super-diffusive and translates into a high \textit{Movement type}.

Fig.~\ref{correlations} indicates that there are less degrees of
freedom than features, which was verified by a principal component
analysis (PCA). On the same trajectory subset, approximately 95\% of
the variance is explained by the first seven principal components. 

\subsection{Statistical procedure}
\label{sec:stats}
\paragraph{Trajectory quality control}
 Prior to statistical analysis, a trajectory quality control is performed. First of all, trajectories resulting from object fusion are discarded. Indeed, trajectories resulting from a fusion are most of the times cell cluster trajectories, rather than cell trajectories. Trajectories which are shorter than 10 frames are also discarded, to ensure that features such as the diffusion coefficient are computed on a sufficiently large number of points. Finally, because we are interested by single cell motility rather than collective motility, all trajectories with more than 5 neighbours in a perimeter of 50 pixels are deleted. This trajectory quality control ensures that cell clusters are not considered, and increases the dataset robustness. This quality controls eliminates $11.6\pm 13.3 \%$ (median$\pm$interquartile range) of cell trajectories per experiment, as estimated on a random subset of 1,000 experiments from the Mitocheck dataset.
\paragraph*{}
HT screening data is organized in batches of experiments which have
been acquired simultaneously. Each batch includes a set of negative
controls, i.e. conditions where no effect is expected. Due to a
non-negligible batch effect, an experiment can only be compared with
controls of the same batch in most of the cases. 

Let us consider an experiment $i$. Following to trajectory feature extraction, it can be summarized as a set of $\Theta$ feature distributions ($\Theta = 15$). The comparison of these distributions with those of controls from the same batch $B_i$, using Kolmogorov-Smirnov 2-sample test, provides a list of p-values $(p_\theta)_{\theta=1\ldots\Theta} $. 

A final statistic $S_{i}$ combining the p-values of all features is  obtained by Fisher's formula :
\begin{equation}\label{FisherFormula}
S_{i}=-2 \sum_{\substack{\theta}}ln(p_\theta)
\end{equation}
As shown on fig.~\ref{correlations}, the features are not independent. Therefore, the distribution of this statistic under the null hypothesis does not follow a chi-squared law with $2\Theta$ degrees of freedom. To assess which values of this statistic should be considered as indicative of altered motility, a sample of the distribution of $S$ under the null hypothesis is then computed by comparing the control experiments  which were not used in the experiment-controls comparisons, with the other controls from the same batch.

In the absence of an explicit form for the null distribution, this sample allows to quantify the intra-batch variations of single cell motility features. The variations can be due to technical artefacts or biological variability. Then, the comparison of the distribution of $S$ statistics obtained from control-experiment comparisons, to the distribution obtained from control-control comparisons, permits the computation of empirical p-values. This enables the detection of hit experiments with regard to single cell motility.  

\paragraph{False discovery rate control}~\\
\label{sec:fdr}
False discoveries are controlled using the Benjamini-Hochberg procedure~\cite{Benjamini1}. Indeed, in the current case, approximately 150,000 statistical tests will be performed. Selecting experiments whose p-value is below 0.05 rigorously means that there will be 5\% false discoveries. Without any adjustment, 150,000 tests will produce 7,500 false discoveries, which is not acceptable. 

There are different ways to adjust p-values. If the statistical tests are independent, the Benjamini-Hochberg procedure~\cite{Benjamini1} is a procedure to adjust p-values and control the false discovery rate. If the tests are not independent, there are other procedures (see for example ~\cite{Benjamini2} or ~\cite{Roquain}). Here, we assume in a first approximation that the tests are independent. Rigorously speaking, they are not: experiments which are performed on the same day share some dependence, which may be the influence of the temperature, the pressure, the passage number of the cells or another experimental variable. We do the hypothesis that we can neglect this local dependence (384 experiments versus 150,000).

%The Benjamini-Hochberg procedure takes as an input a list of M p-values, ordered. Then for each p-value with rank k p(k) you are going to compute p(k, adj) = p(k)*M/k. According to [Benjamini and Hochberg, 1995] this will be <= to the false discovery rate. Neverthless, (p(k,adj)) is not necessarily monotonous with respect to k. As an example, if you have M=1,000 and the first 100 p-values are 0.0001, then the first adjusted p-value will be bigger than the 100th. Hence there is a correction which has to be made, for (p(k,adj)) to be monotonous with k. It's optimistic: here all adjusted p-values before the 100th will be set equal to the 100th. This explains that some p-values have exactly the same values: they were set equal to respect the monotonicity of the adjusted p-values with respect to the initial list of p-values.

\paragraph*{Formal statistical procedure\\}
This procedure is repeated $n$ times to ensure that the final p-value of an experiment $i$ does not depend on the choice of a specific subset of control experiments in its batch%IS THIS BOOTSTRAPPING? no because bootstrapping is sampling with replacement. Here what we do is sampling without replacement to be more robust ($n=5$)
. Here is its formalized description:
\begin{enumerate}
\item {\bf Compute a sample of statistic (\ref{FisherFormula})  under null hypothesis from control-control comparisons.}\\ For each batch $b$,
\item[] \ \ \
 For k in $\{1,\ldots,C_b(C_b-1)/2\}$, where $C_b$ is the number of controls of batch $b$ that passed the quality control
\item[] \ \ \ \ \ a. Randomly split the control experiments in two
  groups $A_{b,k}$ of cardinal $2$, and $B_{b,k}$ of cardinal $C_b-2$
\item[] \ \ \ \ \ b. For each control $j$ of $A_{b,k}$, compute the statistic $S^{0}_{b,k,j}$ (\ref{FisherFormula}) by comparing it to the pooled group of controls $B_{b,k}$

\item {\bf Compute statistics from experiment-control comparisons.} For computation time feasibility, only $n=5$ repetitions corresponding to $n$ splits of the controls set $(A_{b,k}, B_{b,k})$ are selected on each batch for experiment-control comparisons. 
\item[] \ \ \ a. For each repetition k in $\{1,\ldots,n\}$:
\item[]\ \ \ \ \ \ \ For each experiment $i$  belonging to a batch $b$, compute the statistic $S_{k,i}$(\ref{FisherFormula}) by comparing it to the pooled group of controls $B_{b,k}$
\item[] \ \ \  b. Combine distinct iterations. In order to be conservative, we chose the following approach:
\begin{equation}
S_{i} = {\max}_{\substack{k \in \{1\ldots n \}}} S_{k,i}
\end{equation}

\item  For each experiment $i$, compute the p-value $p_{i}$:
\[p_{i} =max \left( \dfrac{card( \{(b,k,j) | S^{0}_{b,k,j}\geq S_{i} \})}
{card( \{ (b,k,j) \})},
 \dfrac{1}
 {card( \{ (b,k,j) \})}\right) \]
\item For each experiment $i$, compute the adjusted p-value $p^\prime_{i}$ to control the false discovery rate (Benjamini-Hochberg procedure~\cite{Benjamini1})
\end{enumerate}
Each experiment is characterized by an adjusted p-value ; significantly different experiments are those whose adjusted p-values are below a certain threshold. An experimental condition is selected as being a hit if 50\% or more of its replicate experiments are significantly different. This is a way of ensuring reproducibility. It amounts to representing an experimental condition by the median of its replicate scores. Since the mean is sensitive to outliers, using the mean of its replicate scores instead of their median would lead to too many false positives.

%Therefore, in the absence of an explicit form for the null distribution, this procedure enables the computation of an empirical null distribution of p-values describing how single cell motility feature distributions vary from a control experiment to another. The $n$ iterations ensure that the final p-value $p_i$ of experiment $i$ does not depend on the choice of a specific subset of control experiments in its batch.
\section{Validation on a simulated screen}
\label{sec:simulation}
\subsection{Screen simulation}
In order to evaluate the performance of our workflow on data for which the groundtruth is
known, we designed a process to simulate a HT screening
experiment. 

In a first step, five types of single cell movements were designed, in
agreement with qualitative observations from the dataset: \textit{random}, \textit{fast-random}, \textit{curbed-directed}, \textit{flip-directed} and \textit{stop-and-go}~(see fig.~\ref{simulation}). 


Let $(d_t,\phi_t)$ be the polar coordinates of the difference vector $m_{t-1}-m_t$
of any two consecutive
points. For \textit{random} movement, $\phi_t$ is
chosen at random and the distance $d_t=\|m_t-m_{t-1}\|_2$ is
drawn from a normal distribution, whose parameters are estimated from
the data. The same holds for \textit{fast-random} with increased
distance $d_t$. For the \textit{curbed-directed} movement type, $d_t$
follows again a normal distribution as for \textit{random} movement,
but the angle is calculated as $\phi_t + \epsilon$ with $\phi_t =
\phi_{t-1} + \Delta \phi_t$, where $\Delta \phi_t$ and $\epsilon$
follow normal distributions, whose parameters are set manually to
visually match some observed trajectories. 

\textit{Flip-directed} and \textit{stop-and-go} are two composite types of movement, where the cells
alternate between different states. The dwelling times in the two
states are random integers with manually fixed ranges (which can be
different for the two states) and are drawn independently for each
trajectory. \textit{Flip-directed} movement corresponds to directed
movement ($\phi_t$ is drawn from a normal distribution) with a 180
degree flip for every state transition. Finally, \textit{stop-and-go}
movement alternates between slow random movement (where $\phi_t$ is
drawn from a uniform distribution)  and fast directed
movement (where $\phi_t$ is drawn from a normal distribution).  
\begin{figure}[ht]
\centering
%\centerline{\includegraphics[width=0.5\textwidth]{trajectories_6.pdf}}
\includegraphics[width=0.5\textwidth]{figures/Walter_295_fig_5.pdf}
\caption{Simulated trajectories: stop-and-go (green), flip-directed
  (red), random (orange), fast random (purple), curbed-directed (blue)}
\label{simulation}
\end{figure}

In a second step, we want to simulate movies (controls and experiments), i.e. sets of
trajectories. For this, we define five movie types with different
proportions of single cell movement types (cf supra). \textit{Normal}
movies account both for 
control movies and experiments in which cell motility is similar to
that of controls. They contain on average $80\%$ of \textit{random} trajectories,
and a mix of the four other trajectory types. This reflects our
observation that in real data, experiments and controls typically contain all possible types
of cell trajectories and that phenotypes are characterized in a shift
in percentage. All other movie types contain (on average) from 50 to 65\%
\textit{random} trajectories, the rest being completed according to
the movie type. For example, movie type \textit{fast} is composed of 30\% of
\textit{fast-random} trajectories, 60\% of \textit{random}
trajectories, and a mix of the three other trajectory types. 

The total number of trajectories in each movie was drawn at random
from real data in the following way: first, a batch is randomly chosen in the data
set. Then, we assign a permutation of the real trajectory numbers from
the experiments of the picked batch to the simulated positions. This enables to include potential batch effects in our simulated data. Furthermore, they match those from the dataset on which we developed this workflow, namely the Mitocheck dataset. The number of trajectories of each movement type in each movie is drawn from
the corresponding movie type multinomial distribution, where the
percentages were defined as described above. 

The third step was the simulation of approximately 50,000 experimental
conditions, which were distributed on 130 plates, and performed in
triplicate as in Mitocheck experimental
setup~\cite{pmid20360735}. For sake of simplicity, triplicates were
supposed to belong to the same movie type. On
each plate, between 5\% and 15\% of the experiments were selected to
be other than \textit{normal} movies. 
%
%
%\begin{table}[!t]
%\caption{This is table caption\label{Tab:01}}
%{\begin{tabular}{llll}\toprule
%head1 & head2 & head3 & head4\\\midrule
%row1 & row1 & row1 & row1\\
%row2 & row2 & row2 & row2\\
%row3 & row3 & row3 & row3\\
%row4 & row4 & row4 & row4\\\hline
%\end{tabular}}{This is a footnote}
%\end{table}

%\section{Experimental validation and application}
%\label{sec:results}
%radiuses $2.6 \mu m$ and $11.7 \mu m$\\
%n=5, combination: max

%We first evaluate MotIW on simulated data (see~\ref{sec:simu_results}). We then apply it to the whole genome-wide screen Mitocheck~\cite{pmid20360735}, which enables us to identify an ontology of 2D cell trajectories (see section~\ref{sec:mitocheck}).%In this latter screen, each gene was targeted by three different siRNAs, and each experimental condition was tried in triplicate.
\subsection{Application to a simulated screen}
%We simulated a whole HT screen, as detailed in section~\ref{sec:simulation}. 
Our workflow successfully recognized more than 98\% of the experiments, as detailed in table~\ref{simu_results}.
\begin{table}[!ht]
\centering
\caption{Results from the application of MotIW to simulated data\label{simu_results}}
{\begin{tabular}{l|c|c|}
 & Recall (\%)& Precision (\%)\\
\hline
\parbox{5cm}{Outlier experiment detection} & $99.2$ & $98.9$\\
\parbox{5cm}{Outlier condition detection} & $99.5$ & $100.0$\\
\hline
\hline
Trajectory clustering & $91.4\pm2.1$ &  $89.4\pm4.8$\\
\hline
\end{tabular}}{}
\end{table}

Our simulation pipeline was also used to estimate how useful the trajectory feature set is to capture the differences between different types of trajectory motion. %The same procedure as for real data was followed. 
500 samples of each trajectory type were simulated, and their features
extracted. A PCA was performed, after which we retained the eigth
first principal components, which explain approximately $95\%$ of the
data set variance. Finally, k-means was applied to the data set with
$k=5$. Many simulation parameters (e.g. each track length) are chosen
at random, and k-means' results depend on its initialization: the
procedure was therefore repeated 10 times. The results are presented
in table~\ref{simu_results}. Although distinguishing trajectory types
is subject to some errors, it shows that the whole pipeline is robust
enough to identify experiments in which cell motility is significantly
different. 

We therefore conclude that MotIW is capable of identifying trajectory
clusters in an unsupervised way. Hence, we are confident that this
methodological workflow will allow the identification of migratory behaviors in HT live cell imaging data sets. Moreover, we believe that the general strategy of identifying hit experiments prior to cluster analysis
might be useful for unsupervised approaches to HCS data. 

This strategy can indeed also be seen as a way of intelligently downsampling the data to a reasonable size. Compared to random sampling, it has the advantage of enriching the data set in extreme cases. In a supervised setting, this occurs as a natural result from the annotation process: the numbers of samples in each class of the training set rarely reflect their proportion in the whole dataset. The training set is therefore most of the times enriched in rare classes. This seems to be beneficial as well for unsupervised learning approaches to large biological data mining.



