\lhead{Chapter 4 - \emph{Xenobiotic screen}}

\chapter{Xenobiotic screen}

Environmental health consists in studying the impact of Man's environment on his health. This can be done following either one of two major paradigms: \textit{Epidemiology} and \textit{Toxicology}. The former deals with human populations, looking for significant link between past exposure and present pathologies. Toxicology can itself be \textit{in vivo}, \textit{in vitro} or \textit{in silico}, depending whether one chooses to study the impact of a precise exposure on a population of living organisms, a population of cells, or based on chemical descriptors of the exposure.

Causal links can be quite delicate to establish in Epidemiology. There is a great number of variables which are involved (e.g. genetic or behavioral) ; the effects can have a weak penetration and are often delayed by a certain number of years with respect to the exposure. To mitigate these effects, Toxicology enables to select the chemical (or xenobiotic\footnote{A xenobiotic is, with regard to a species, any compound which was not produced by an individual of this species.}) of interest, as well as precisely control the experimental settings.

However, Toxicology is currently facing two major challenges:
\begin{itemize}
\item Around 100~000 new compounds are synthesized each year. There is therefore the need for high-throughput (HT) and safe toxicity tests.
\item European regulations are stricter and stricter with animal testing, hence the need for novel \textit{in vitro} toxicity tests.
\end{itemize}
\paragraph*{}	
This led us to think of importing the technique of drug screening from pharmacological Toxicology, replacing prospective drugs with xenobiotics. The basic idea of screening is to perform a given assay on hundreds of compounds in parallel.

Classical \textit{in vitro} toxicological screening procedures have been in use for some time, such as the Comet assay for DNA damage, which is known since 1984~\cite{pmid6477583}. This type of test is now routinely done in a HT setup. However, it provides very crude information compared to what high content (HC) assays would indicate regarding for example, cell cycle modulation following BPA exposure. Subtler tests are being developed in a HT setup, either endpoint~\cite{pmid24772387},~\cite{pmid24610750} or real-time assays~\cite{pmid21516415}, \cite{pmid24141454}. This was recently made possible  by technical and computational progresses.

Nevertheless, the majority of new \textit{in vitro} toxicological methods are not HC \textcolor{red}{\bf [*** I do not understand the footnote. ***]} \footnote{3 out of 10 on the relevant results of the PubMed searches "environmental AND cellular AND (screening[Other Term] OR High throughput/high content assays[Other Term])" and "time-lapse AND toxicology" on the 3/19/2015.}, i.e. they do not allow detailed observation of phenotypes at the single cell level. Moreover, there are many biological processes which are best studied with time-lapse microscopy. Such methods are common practice in molecular biology and have been even scaled up to be applicable in a HC setup. Surprisingly, this type of experiment is still rarely used in Environmental Toxicology - regardless of the throughput. When it is, data is manually analyzed most of the time (e.g.~\cite{pmid17949680},~\cite{pmid15388243}, or~\cite{pmid24263567}).

%whose study not only requires access to single cell phenotypes, but 
%Time-lapse experiments are a specific type of HC experiment which deals with cell videos rather than fixed images, and is about to become a common procedure in Molecular Biology. This type of experiment is still rarely used in Environmental Toxicology - regardless of the throughput. When it is, data is manually analyzed most of the time (e.g.~\cite{pmid17949680},~\cite{pmid15388243}, or~\cite{pmid24263567}).

However, time-lapse experiments would be a significant improvement over endpoint assays, as they enable for example to assess event sequences following exposure rather than record cell death. Environmental Toxicology time-lapse data was therefore newly generated, in order to assess whether HC time-lapse screening is applicable in this context : is this approach relevant for toxicity detection and characterization of environmentally relevant compounds? Time-lapse HCS usability in this context would lead to the potential development of a time-lapse HC-HT assay for Environmental Toxicology. %Indeed, until recently, Toxicology experiments were either HC and low-throughput, or low-content and HT.

Hence five well-known xenobiotics were selected and screened for their effects on nuclear motility and nuclear morphology. The whole pipeline is illustrated fig.~\ref{xbsc_workflow} (and the experimental settings are detailed fig.~\ref{exp_setting}). Briefly, cells were chemically exposed prior to image acquisition over time. Cells were segmented on each image of each experiment using the open-source software CellCognition~\cite{cellcognition}. Object features were extracted using the same software, for two purposes: nuclear tracking and nuclear morphology classification. 

Nuclear tracking was performed as described in the methodological article~\cite{motiw}. This step was followed by trajectory feature extraction, and statistical hit detection, as described in the same article.

CellCognition was used to establish a training set of annotated nuclear morphologies, to train a classifier and apply this classifier to each nucleus in the data set. This allowed us to describe each experiment by a set of class percentage time series, whose comparison with control time series allow us to detect significant differences.

As this was a proof of concept experiment, the goal was slightly different than that when applying MotIW on the Mitocheck dataset. In the latter case the goal was to select relevant genes for nuclear motility with high confidence, which explains why an ad hoc statistical procedure had to be developed to make sure that p-values were not over-estimated. In the case at hand, the goal was rather to select experimental conditions with mild-to-high confidence for performing confirmatory experiments. Our goal was therefore to obtain a ranking of all conditions with respect to the tested endpoint (motility or cell cycle) rather than computing absolute p-values.

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.25]{figures/workflow_xb_complet_fused_calques.png}
\caption{Xenobiotic screen complete workflow}
\label{xbsc_workflow}
\end{figure}

\section{Materials and methods}
\label{protocoles}
\subsection{Experimental work}
\subsubsection{Chemicals}
TCDD was bought from LGC Standards (Molsheim, France), TGF~$\beta$1 from R\&D Systems\texttrademark (Minneapolis, MN, USA), BPA, MeHg and PCB153 from Sigma Aldrich\up{\textregistered} (Saint-Louis, MO, USA). $\alpha$-Endosulfan was bought from Cambridge Isotope Laboratories, Inc. (Tewksbury, MA, USA) and DMSO from Merck Millipore (Billerica, MA, USA).

The following media were used:
\begin{itemize}
\item normal medium: DMEM (Gibco\up{\textregistered}, Life Technologies\texttrademark, Puteaux, France) with phenol red and supplemented with 10\% fetal calf serum (FCS), 200 units/ml penicillin, 500 $\mu$g/ml streptomycin, 3g/ml glutamin, 10$\mu$g/mL insulin and 0.1nmol/mL %Milieu avec Aa non essentiels 0.1nM final et insuline 10microgramme par ml.
of non-essential amino acids solution (all from Life Technologies\texttrademark), and 0.5 $\mu$g/ml fungizone (Squibb, Princeton, NJ, USA),
\item imaging medium: CO$_2$-independent medium (Gibco\up{\textregistered}) supplemented with 10\% FCS, 200 units/ml penicillin, 500 $\mu$g/ml streptomycin, 3g/ml glutamin, 10$\mu$g/mL insulin and 0.1nmol/mL %Milieu avec Aa non essentiels 0.1nM final et insuline 10microgramme par ml.
of non-essential amino acids solution, and 0.5 $\mu$g/ml fungizone.
\end{itemize}

\subsubsection{Cell culture}
The human mammary tumor cell line MCF-7 (ATCC\up{\textregistered} Catalog N\up{o}HTB-22\texttrademark)  was maintained in normal medium as defined above. %Forty-eight h before any experiment, the medium was removed and replaced by DMEM without phenol red (Life Technologies\texttrademark) with 3\% charcoal-treated calf serum (i.e. desteroidized calf serum), and the same concentrations of penicillin, streptomycin, and fungizone as described above\footnote{Medium called "experiment medium" in the following.}. 
\subsubsection{Cell transfection and clonal selection}
MCF-7 cells were transfected with two plasmids : one containing human histone H2B fused to the gene encoding a red fluorescent protein (mCherry), isolated from Discosoma species (Addgene, plasmid \#21045), one containing human membrane lipid Myr/Palm fused to the gene encoding the green fluorescent protein (GFP) of Aequorea victoria (Addgene, plasmid \#21037). The aim was to generate a stable line constitutively expressing H2B-mCherry and Myr/Palm-GFP.

On the day before transfection, MCF-7 cells were seeded into 10cm dish with normal medium (2 millions per dish). On the day of transfection, cell medium was replaced with 2mL of normal medium and a mix composed of 72$\mu$l Lipofectamin\up{\textregistered} 2000 reagent and 24$\mu$g of total plasmid DNA (either H2B-mCherry alone, Myr/Palm-GFP alone or both), completed to a volume of 3mL with Optimem (Life technologies\texttrademark). Cells were then incubated for 5 hours at 37\up{o}C, after what 5mL of normal medium was added. 
Antibiotic selection started 7 days after transfection, with 1mg/mL of neomycin and 1$\mu$g/mL of puromycin added to normal cell medium ; selection medium was replaced every other day.

Clonal selection was realized by infinite dilution: three weeks following the beginning of antibiotic selection, transfected cells were seeded in two 96-well plates with 64 wells at 0.3 cell/well, 64 wells at 1 cells/well and 64 wells at at 3 cells/well. Once clones had suffienctly grown, a few clones were selected based on their level of plasmid expression. They were tested for the expression of the following genes with and without exposure to 25nM TCDD for \textbf{** hours}: Aryl hydrocarbon receptor  (AHR), Cytochrome P450 1A1 (CYP1A1) and E-cadherin genes. Most clones responded as expected (increased expression of AHR and CYP1A1 and decreased expression of E-cadherin - data not shown). One clone was discarded.

Following this step, modified cells were maintained in normal medium with 1mg/mL of neomycin and 1$\mu$g/mL of puromycin. Hereafter, "MCF-7 cells" refers to a selected clone of such modified cells.

%\paragraph{RNA extraction, reverse transcription and RT-qPCR} Total RNAs were extracted using the RNeasy mini kit (Qiagen, Les Ulis, France) and reverse transcription was performed using the cDNA high-capacity archive kit (Applied Biosystems) according to the manufacturer's instructions. The primers used for the real-time PCR are available on request. Quantitative real-time PCR was carried out in a 10-ml reaction volume containing 40 ng of cDNA, 300 nM of each primer and ABsolute QPCR SYBR Green (Abgene, Villebon sur Yvette, France) using an ABI Prism 7900 Sequence Detector system (Applied Biosystems). PCR cycles consisted of the following steps: Taq activation (15 min, $95^\circ$C), denaturation (15 s, $95^\circ$C) and
%annealing and extension (1 min, $60^\circ$C). The threshold cycle (Ct) was measured as the number of cycles for which the reporter fluorescent emission first exceeds the background. The relative amounts of mRNA were estimated using the DDCt method with the gene RPL13A (coding for 60S ribosomal protein L13a) for normalization.

\subsubsection{Production of 96 well-plate for imaging}
48h prior to imaging, MCF-7 cells were seeded in normal medium into one 96 well-plastic plate, at a density of 6,000 cells per well. The plate was placed back in the incubator at constant temperature ($37^\circ$C) and CO$_2$ pressure (5\%). 24 hours prior to imaging, dilutions (cf table~\ref{dilutions}) of selected compounds with constant solvent percentage were freshly prepared in imaging medium. Cell medium was changed with 198$\mu$L of imaging medium and 2$\mu$L of chemical dilution or solvent dilution per well. Six control wells for each solvent and three wells with cell medium only were put on each plate. Plate design was not random, but control wells were not grouped (see fig~\ref{plate_setup} for an example of a plate setup).

The plate was placed back in the incubator. Immediately before image acquisition, the plate was sealed using an adhesive optical film (\textbf{ref. **}). This procedure is illustrated on figure~\ref{exp_setting}.

\begin{figure}
\centering
\includegraphics[scale=0.3]{figures/experimental_setting.png}
\caption{Illustration of the experimental settings}
\label{exp_setting}
\end{figure}
\begin{figure}
\centering
\includegraphics[scale=0.5]{figures/plate--271214.png}
\caption{Example of a plate setup. \textit{Cl1}: clone number, \textit{Indpt 10}: $CO_2$-independent cell medium with 10\% FCS.}
\label{plate_setup}
\end{figure}
\subsubsection{Time-lapse imaging}
Images were acquired every 15 minutes in each well for forty-eight hours, with an automated epifluorescence microscope (Axio Observer Z1; Zeiss, Oberkochen, Germany) with motorized objectives in z-axis (resolution 10nm) and using 10x objective (EC Plan-Neofluar;0.3 M27). Each well was imaged 800ms at lengthwave $\lambda = 555nm$ (mCherry) and 300 ms at $\lambda = 470nm$ (GFP).

The microscope is integrated into a microscope incubation chamber to provide constant temperature (+37\up{o}C), which was turned on at least one hour prior to the beginning of image acquisition. Zeiss software ZEN2011 was used for data recording. Focus was done manually, and was updated by definite focus.
\subsubsection{Phototoxicity assays}
One plate was prepared with 12 wells following the above-described procedure, except that no chemical was added prior to image acquisition. Images were acquired for 24h, with the four different imaging conditions :
\begin{itemize}
\item no imaging
\item 500ms at $\lambda = 555nm$, 300 ms at $\lambda = 470nm$
\item 1~000ms at $\lambda = 555nm$, 300 ms at $\lambda = 470nm$
\item 1~500ms at $\lambda = 555nm$, 300 ms at $\lambda = 470nm$
\end{itemize}
2$\mu$L of \textit{alamarBlue\texttrademark Cell Viability Assay Reagent} (Thermo Scientific, Rockford, IL, USA) were then added to each well. Following 2h of incubation at $37^\circ$C, absorbance was measured at $\lambda = 570nm$ and $600nm$ using an EnSpire\up{\textregistered} (PerkinElmer, Waltham, MS, USA). The index of cell viability was computed following the manufacturer's formula.

\subsubsection{Chemical dose choice}
Doses were chosen so that the lower end is close to human exposure levels, and that the higher end is not cytotoxic.

The first goal was attained through a literature review, whose results can be seen in appendix, section~\ref{literature_review}. The second goal was attained through cytoxicity tests. One plate was prepared with 76 wells as described above, although with 5,000 cells per well. 24h after seeding, cells were exposed either to solvents, either to doses 6 to 10 of selected compounds. 24h after exposure, 2$\mu$L of \textit{alamarBlue\texttrademark Cell Viability Assay Reagent} were added to each well. After 24h of incubation, fluorescence was measured in each well at $\lambda = 555nm$, and cell viability index was computed following the manufacturer's formula. In the end, 9 to 10 doses for each of the five chosen xenobiotics were selected, the total summing to approximately 50 different conditions to which cells were exposed.

\subsection{Bioinformatics methods}
\label{interface}
\subsubsection{Web-based user interface for result visualization}  A web-based user interface was designed for raw  and quality control data visualization. It is accessible at the following address: \href{http://olympia.biomedicale.univ-paris5.fr/plates/}{http://olympia.biomedicale.univ-paris5.fr/plates/} (login: \textit{user}, password: \textit{xbscreen}). It was implemented using \href{https://www.djangoproject.com/}{Django} web framework, the programming language \href{http://www.python.org}{Python 2.7}, and runs under Linux-Apache web server and mod\_wsgi module. \href{https://sqlite.org/}{SQLite} was used for storing experimental metadata (plate setups, experimental conditions such as cell medium or the percentage of FCS). The database was built as visible on fig~\ref{db}.

Briefly, each well is linked to a unique plate, a unique condition (medium and percentage of FCS) and a unique treatment (xenobiotic and dose). As the data was (crudely) password-protected, a second database contains logins and passwords, as well as admin permissions.

After logging in, any user has access to the list of plates in anti-chronological order. A plate page displays the plate setup, as well as some overall features of the experiments, such as initial number of objects or the proliferation rate in each well. This enables to see a significant geographical bias, which could be due to chemical exposure or the experimental settings. In the latter case, the plate should not be used for analysis and the experimental protocol modified ; such visualization tools were useful for designing the protocol. 

By clicking on a particular well on any image of the plate page, one accesses per-well information: well experimental conditions, well raw movies, and time evolutions of mean intensity, percentage of out-of-focus objects, number of cells, number of objects, and percentage of objects in all classes (as detailed below).

\begin{figure}
\centering
\includegraphics[scale=0.4]{figures/schema_db2.png}
\caption{Diagram of the databases for experimental metadata storage}
\label{db}
\end{figure}

%The WCTDS has been implemented by using Django
%web framework (https://www.djangoproject.com/), R 3.0
%(http://www.r-project.org/), Python 2.7, and Linux shell pro-
%gramming, and it runs under Linux-Apache web server and
%mod wsgi module. MySQL is used to build a database for
%communicating between user input and the data storage.
%Python and Django are used to implement the web interface.
%The whole software runs under Linux shell. The computa-
%tional core, including mathematical models, data processes,
%and result generation, is implemented by R, which was
%detailed in our previous publication [9]. To speed up the
%computation, parallel computation was implemented to run
%the mathematical models.
%To reduce the complexity of its usage, WCTDS runs all
%functions and computations behind the screen under Linux
%shell and only requires a simple data frame as input. The sub-
%mitted data frame is directly passed by Python functions to R
%serial functions, including quality check, matrix preparation,
%parallel computation of math models, result summary, graph
%plots, and compressing all results in a zip file, which is sent
%back to web server coded by Python and Django for user
%download.

\subsubsection{Quality control}
Due to microscope hardware and/or software instability, images showed mean intensity variation on both channels. Hence, images $t$ whose mean intensity on the mCherry channel $I_t$ verified the following inequality were not considered for further analysis, where $\sigma_I $ is the standard deviation of $(I_t)_{t=1\ldots T}$:
\[ |I_t- \dfrac{\sum_{i=0\ldots 10} I_{t+i} }{10}| > 3\sigma_I  \]

Furthermore, a threshold of $c$ cells at the beginning of the movie, and maximum $p$\% out-of-focus objects were used to further remove unexploitable movies.   
We fixed the threshold after visual inspection to $c=23$ and $p=37$. Out-of-focus objects and cells that were neither artefacts nor out-of-focus objects were identified following segmentation, feature extraction and classification as described below.
%image quality control, experiment quality control

\subsubsection{Object segmentation}

Object segmentation was done using a newly-designed plugin implemented
in the open-source software CellCognition~\cite{cellcognition}. MCF-7
cells are smaller than HeLa cells and tended to form clusters in our
experiments. While the method described in ~\ref{sec:motiw_seg}
and previously published in several papers, e.g. in
\cite{cellcognition}, is in principle capable of splitting clustered
nuclei, we felt that the filtering of the distance transform, 
which ultimately influences the decision on whether to split or not, was suboptimal. 
Here, we used morphological dynamics to improve the splitting step of
this segmentation method.

The first steps of the method are therefore identical to what we have
presented in ~\ref{sec:motiw_seg}: images are prefiltered (here by a
median filter) and we assign to each pixel the difference of its value
to the average in a window centered in the pixel. This average value
can be efficiently calculated with integral images. By applying a
global threshold to the residue image, we obtain a first segmentation
result which gives accurate results for isolated nuclei, but which
tends to segment close nuclei together as a single object. 

The last step is to calculate the Watershed transformation on the
inverse distance map which is a
standard technique to divide close convex objects after
segmentation~\cite[Chapter Geodesic segmentation]{lantuejoul}. This
method splits the binary segmentation
result in as many objects as there are local minima in the inverse
distance map. As small irregularities in the contours can lead to such
minima, it is often necessary to apply a filter on the distance map in
order to avoid oversegmentation. One option is to use a simple
Gaussian filter, as proposed in ~\cite{Wahlby2002} and
~\cite{cellcognition}. However, this does not give you an intuitive
control over which minima are really kept, and even worse: it is not
even guaranteed that larger filters suppress necessarily more minima. 
Here, we propose to use morphological dynamics for this
purpose~\cite{Soille:2003:MIA:773286}.  While this technique is widely
used in the morphology community, it is to our knowledge not used for
the splitting of cells, even though it perfectly applies to this
problem. 

Morphological dynamics assign to each local minimum the value at which
it fuses to a region coming from a minimum with lower value (the
dynamic of the lowest minimum is set to $\infty$). As the watershed
algorithm iterates through the values in an ordered way, this value is
identical to the minimum height that has to be passed to reach a lower
minimum. Let $p_{i,j}$ be a path that joins minima $i$ and $j$, the dynamic of minimum $i$ is the following:
\[ dyn(i) = \min_{\substack{p_{i,j} \\ f (j)<f (i)}} \max_{\substack{x\in p_{i,j}}} (f(x) - f(i))\]

Hence, to avoid the usual over-segmentation produced by the watershed
algorithm, we only use the subset of minima with dynamic larger than a
certain threshold. The number of objects decreases as this threshold
increases, and the control is intuitive: small concavities produce
local minima with relatively low dynamic (independently from their
spatial arrangement or the size of the objects). 

The computational cost of the morphological dynamics is the same as
the watershed algorithm. Depending on the size of the data sets, this
is not negligible, even though it compares favorably to 
smoothing filters, as they were used in this context. In order to optimize this still further, we
implemented the dynamic filter in such a way that it is directly
combined with the watershed algorithm, thus further reducing the
computational complexity. Indeed, the criterion can be checked each
time a pixel is about to be assigned to the watershed line, and
consequently no additional flooding step is necessary. 

%Briefly, the inverse distance map of a binary image $X$ assigns to each of its points $x$ the inverse of the distance to the nearest background point: 
%\[ D(x) = \dfrac{1}{\min_{\substack{y\not\in X}} d(x, y)}\]
%d can be any arbitrary metric, for which popular choices are $\parallel\cdot\parallel_\infty$ (the maximum distance), $\parallel\cdot\parallel_1$ (the $L_1$ distance) or $\parallel\cdot\parallel_2$ (the Euclidean distance). 
%The Watershed transformation partitions the image plane into disjoint regions, which are separated by a one-pixel-wide line (the watershed line). This is done by starting from seeds, the local minima of the image (i.e. regions with constant value, surrounded by pixels with strictly greater value) . The watershed algorithm iterates over the possible values the image mask f can take. Starting with the seeds, it extends each region with the pixels of the current value t. If during this extension a pixel
%could be associated to two regions (i.e. if in the neighborhood of the pixel with value t,
%there are at least two pixels with different region appartenance), the pixel is part of the
%watershed line.
%
%in principle other regions
%could be chosen, too (marker controlled watershed algorithm)

Finally, an object filter is applied to eliminate the objects that are (or whose mean intensity is) too small.

%i. pre-filtering of noise. High frequency signal (in space)
%ii. background subtraction. Low frequency signal (in space)
%iii. Watershed distance to merge objects
%iv. 
\subsubsection{Object feature extraction}
Object feature extraction was done using the open-source software CellCognition~\cite{cellcognition}, as previously described~\cite{Walter2010}. Briefly, for each object on each image, approximately 240 features are extracted, characterizing their shape and texture. These features enable to classify nuclei in user-defined nuclear phenotypic classes and to track them over time.

\begin{table}[!ht]
\caption{Nuclear morphology classes with examples. The \textit{artefact} and \textit{cluster} examples are shown with segmentation contours.}
\label{classexamples}
\begin{tabular}{|ll|}
\hline
\multicolumn{2}{c}{Normal classes}\\
\hline
\textit{Interphase}&\includegraphics[scale=1]{figures/cut_inter1.png}\ \includegraphics[scale=1]{figures/cut_inter2.png}\\
\textit{Pro-metaphase}&\includegraphics[scale=1]{figures/cut_promet1.png}\ \includegraphics[scale=1]{figures/cut_promet2.png}\\
\textit{Metaphase}&\includegraphics[scale=1]{figures/cut_met1.png}\ \includegraphics[scale=1]{figures/cut_met2.png}\\
\textit{Anaphase}&\includegraphics[scale=1]{figures/cut_anap1.png}\ \includegraphics[scale=1]{figures/cut_anap2.png}\\
\textit{Apoptosis}&\includegraphics[scale=1]{figures/cut_apop1.png}\ \includegraphics[scale=1]{figures/cut_apop2.png}\\
\hline
\multicolumn{2}{c}{Aberrant morphology classes}\\
\hline
\textit{Frozen}&\includegraphics[scale=1]{figures/cut_frozen1.png}\ \includegraphics[scale=1]{figures/cut_frozen2.png}\\
\textit{Cluster}&\includegraphics[scale=1]{figures/cut_cluster1.png}\ \includegraphics[scale=1]{figures/cut_cluster2.png}\\
\textit{Folded}&\includegraphics[scale=1]{figures/cut_folded1.png}\ \includegraphics[scale=1]{figures/cut_folded2.png}\\
\textit{Micronucleated}&\includegraphics[scale=1]{figures/cut_micronu1.png}\ \includegraphics[scale=1]{figures/cut_micronu2.png}\\
\textit{Polylobed}&\includegraphics[scale=1]{figures/cut_poly1.png}\ \includegraphics[scale=1]{figures/cut_poly2.png}\\
\hline
\multicolumn{2}{c}{Technical problem classes}\\
\hline
\textit{Out-of-focus}&\includegraphics[scale=1]{figures/cut_focus1.png}\\\
\textit{Artefacts}&\includegraphics[scale=1]{figures/cut_artefact1.png}\\
\hline
\end{tabular}
\end{table}

\subsubsection{Object classification}
Object classification was also performed using CellCognition. The
class definitions are illustrated in table~\ref{classexamples}. The
set of morphological classes is supposed to cover the morphological
variability of the screen. The set therefore contains wildtype
morphological classes, such as the morphologies corresponding to the
different mitotic phases and aberrant morphologies indicating the
presence of a phenotype. As our screen consisted in 50 conditions, we
almost exhaustively inspected the dataset and are therefore confident
that no aberrant nuclear phenotype was missed. 

%By default, phenotypic classes are the mitotic classes which the time-lapse permits to observe with a sufficient precision : \textit{interphase}, \textit{pro-metaphase}, \textit{metaphase} and \textit{anaphase} in our case, to which \textit{apoptosis} as well as \textit{out-of-focus} objects and \textit{artefacts} are added. The latter classes are indeed present to various extents in all videos. To these shall be added any aberrant phenotype that can be observed in a visual inspection of the dataset. 

In detail, \textit{Clusters} are clustered nuclei which the
segmentation algorithm failed to split. \textit{Folded} nuclei
represent elongated or round nuclei with two shades of
grey. \textit{Frozen} nuclei are nuclei whose DNA shows a
heterogeneous condensed pattern, persistent over time. Frozen nuclei
either remain in the same class or lead to 
\textit{apoptosis}. Biologically, they might correspond to dying
nuclei and resemble nuclei experiencing phototoxicity (personal
communication, Beate Neumann, EMBL Heidelberg,
Germany). But as it remains unclear why phototoxicity is not more
generally observable in our data set, these cells might have been sensitized by the
xenobiotic. We therefore believe that this class does not translate a
simple technological artifact. 

%They are most probably
%dying nuclei and resemble nuclei experiencing phototoxicity (as kindly
%pointed out by Beate Neumann, EMBL, Heidelberg, Germany). 
%We chose the
%names "\textit{cluster}", "\textit{folded}" and "\textit{frozen}"
%following our visual observations. 

A training set was annotated, containing 2,576 nuclei. Support Vector Machines (SVMs) were used for classification, as they work well for nucleus phenotypic classification (\cite{kovalev} for a comparison of classification algorithms in this context, and for application e.g.~\cite{cellcognition},~\cite{Walter2010}). An RBF (Radial Base Function) kernel SVM was trained, whose parameters were obtained by grid search, using Cell Cognition's interface ($\gamma=2^{-7}$, $C=8$).% The overall classifier accuracy is 65.5\% (10-fold cross validation). 

This step provides us with a representation of each video as a set of time-series, which are the evolution of the percentage of nuclei in each phenotypic class over time. The distance of an experiment $i$ to its reference set $j$ for class $obj$ is the following:
\[
d^{obj}_{i,j} = \int_0^{T} (\% obj_{i,t} - \% obj_{j,t} )~dt
\]
Maxima are less robust to outlier points which could arise in any of
the two time series than integrals. Therefore, we chose to replace the
maximal difference between the two time series which is used in
phenotypic scores~\cite{Walter2010} by the integral of all
differences, as the xenobiotic screen data set is relatively noisy. 

Due to the visual similarities between \textit{Micronucleated} and \textit{Polylobed} nuclei in our dataset, these classes were pooled together for computing distances. The corresponding distance is named \textit{Micronucleated} in the following.

\subsubsection{Object tracking and trajectory feature extraction} Those steps were performed as described in the methodological article~\cite{motiw}.


\begin{table}[!ht]
\caption{Chemical dilutions}
\vspace{0.4cm}
\label{dilutions}
\begin{tabular}{|l|l|l|l|}
\hline
Chemical & Solvent & \parbox{3cm}{Final solvent percentage (vol)} & Doses (nM) \\
\hline
BPA & DMSO & $1.0~10^{-1} $ &0.1, 1, 10, 50, 100, \\
&&&1~000, 5~000, 10~000, 50~000\\
\hline
Endo & DMSO & $2.0~10^{-1} $ &1, 10, 50, 100, 500,\\
&&& 1~000, 5~000, 10~000, 50~000, 100~000\\
\hline
MeHg & DMSO & $1.0~10^{-3} $ & 0.01, 0.1, 1, 5, 10,\\
&&& 50, 100, 500, 1~000\\
\hline
PCB153 & DMSO & $3.6~10^{-1} $ &0.1, 1, 10, 50, 100,\\
&&& 1~000, 5~000, 10~000, 50~000,100~000\\
\hline
TCDD & Nonane &$3.2~10^{-2} $ & 0.001, 0.01,	0.025, 0.1, 0.25,\\
&&& 1, 10, 25, 50\\
\hline
\end{tabular}
\end{table}
\section{Results}
\paragraph{Preliminary choices}
After testing a few clones for the expected behaviour in response to TCDD exposure, one clone was selected and five plates were imaged following the described procedure, producing 415 videos. In the following, each plate is named after the day image acquisition was launched. The quality control eliminated 22\% of the experiments, leaving 324 experiments for analysis with three biological replicates per condition minimum.

Due to the observed high variability in control trajectory statistics on the different plates (cf fig.~\ref{control_heatmap}), the reference was chosen to be the whole plate as opposed to control wells only. This is a valid choice as long as there is no bias in the distribution of chemical conditions (and possibly results) on distinct plates, and most wells do not show any effect~\cite{pmid19644458}. 
\begin{figure}
\centering
\includegraphics[scale=0.4]{figures/heatmap_control_trajfeatures_medstandardized.png}
\caption{Trajectory feature heatmaps corresponding to control wells. Each line corresponds to an experiment, whose plate and name are indicated. Each column corresponds to a trajectory feature. A robust normalization (with median and inter-quartile range) was applied, using all plate, which still permits to see that control responses vary from well to well and plate to plate.}
\label{control_heatmap}
\end{figure}

\subsection{Motility study}
\label{sec:xb_motility}
MotIW was applied to this dataset, which as described in~\cite{motiw} enabled to go from a set of nuclear trajectories to a single statistic for each experiment. However, this statistic was not evenly distributed with respect to the plates. This was measured by a Mann-Whitney U test comparing the list of statistics for one plate with the list of statistics for all remaining plates. Indeed, plates 271214 and 271114 respectively output p-values of 0.06 and 0.02 at this test.

In the Mitocheck study, all experiments from all plates were ranked together ; a p-value threshold was set ; conditions which were more than 50\% of the time under that threshold were considered as significantly modifying nuclear motility. 

In the case at hand, statistics from all plates cannot be ranked together because of an important batch effet. Hence, the approach which was chosen is that of the \textit{RankProduct}~\cite{pmid15327980}. Briefly, this approach consists in formalizing the following idea: we are interested in conditions which have consistently high statistics on the different plates. Our goal is therefore to compute their rank in the statistic list of each plate, and its variations depending on the plate. The \textit{Rank Product} statistic of a condition $c$ is the following, where $pl.~i$ is the $i^{th}$ plate and $card(i)$ the number of experiments performed on the same plate\footnote{If a condition was replicated on the same plate, we used\\
 $rg(c,~i)=median(\{ rg(c_j,i)|j$ technical replicate of $c$ on $i\} )$.}: 

\[RP(c) = \prod_{\substack{pl.~i}} \dfrac{rg(c,~i)}{card(i)} \]

Intuitively, the \textit{Rank Product} of a condition which significantly alters nuclear motility is going to be small. Empirical p-values for the \textit{Rank Product} statistics are computed by permutation, that is, each plate trajectory statistics are permuted $N$ times and the \textit{Rank Product} statistics for each condition computed each time. This produces the empirical null distribution of the \textit{Rank Product} statistics, that is, the distribution of statistics under the hypothesis $H_0$ that no condition alters single nucleus motility more than the average response of all conditions (which was observed to be biologically non-interesting). Empirical p-values are then the proportion of permuted \textit{Rank Product} statistics which are bigger.

Selecting conditions whose empirical p-values are smaller than $0.05$ ($N=10,000$ permutations) produces the following result:
\begin{table}[!ht]
\centering
\begin{tabular}{|l|r|c|l|}
\hline
Condition & Dose & P-value & Example\\
\hline
Endo,10 &$100\mu M$ &0.0001&Supp. movie 1\\
BPA,9 &$50\mu M$ &0.0001 & Supp. movie 2\\
PCB,10 & $100\mu M$ &0.0028&\\
Endo,9 & $50\mu M$ &0.016&\\
MeHg,9 & $1\mu M$&	0.042&\\
PCB,9 & $50\mu M$ &0.048&\\
\hline
\end{tabular}
\end{table} 				%SUPP MOVIE 1 : 271214 w13
%BPA_9 		0.0001					201214 w61
%PCB_10 	0.0028
%Endo_9 		0.0162
%MeHg_9 	0.0416
%PCB_9 		0.0475

Rather than peculiar movement types, according to our approach, the
consistent results are conditions which are so strong as to freeze any
nuclear motion (cf. supplementary movies 1 and 2). We therefore
conclude that motility is significantly altered, albeit not primarily:
measured motility alterations result from potent effects on cell
viability. In contrast, motility alterations in Mitocheck are not coupled to cell
death or cell division phenotypes. Consequently, this confirms that
the identified genes are candidates for cell motility regulators: they do not
trigger motility alterations as a secondary effect of other
alterations, as it seems to be the case here. 

\subsection{Phenotypic study}
\paragraph{Phenotypic class selection}
Phenotypic classes were chosen after an almost exhaustive visual
inspection of the dataset. The first result is that except
\textit{frozen} nuclei which were observed in medium and high dose
experiments only, no other striking phenotypes were observed following
xenobiotic exposure only. Indeed \textit{micronucleated} and
\textit{polylobed} nuclei are present in all wells at a non-negligible
base level, and do not significantly appear following xenobiotic
exposure. 

\paragraph*{}
As opposed to the motility case, no specific plate distance distribution for any of the classes is significantly different to that of all other plate distance distribution. Hence distinct plate distances can be directly compared. 

When no effect is expected, most cells are in interphase. Therefore, strong effects will be visible in a decrease of \textit{interphase} percentage. A preliminary step consists in looking at conditions for which \textit{interphase} distance is especially low. The \textit{interphase} distances are represented on fig.~\ref{interphase}. One can observe that only high doses (plain red dots) are consistently under the rest of the scatter plot. This depletion of interphases is explained by an increase in \textit{frozen} and \textit{apoptotic} nuclei (cf. the \textit{frozen} distance scatter plot on fig.~\ref{interphase}).

The observation of other class distance distributions does not provide other results as to possible consequences of xenobiotic exposure on cell division, and especially low dose exposure: there is no low dose condition which show a consistent effect over distinct plates for any phenotypic class. Graphs are shown in annex, section~\ref{phenotypic_annex}.

These observations are supported by the computation of \textit{Rank product} statistics for \textit{Interphase}, \textit{Frozen} and \textit{Micronucleated} nuclei (cf. table~\ref{dist_pheno}). The significant increase in \textit{Micronucleated} nuclei following exposure to PCB at the first dose could be visually confirmed in 1 out of 4 experiments only. Furthermore, the level of micronucleation in the latter experiment is comparable to the level that can be observed in other experiments with \textit{nothing} or \textit{Nonane}. Indeed, there is a significant base-level of aberrant cell divisions, as is stressed by the small p-value for wells containing nothing (\textit{Rien}) and visual inspection of the dataset.
\begin{table}[!ht]
\centering
\caption{\textit{Rank product} p-values for different phenotypic distances (<0.05)}
\label{dist_pheno}
\bigskip
\begin{tabular}{|l|r|c|l|}
\hline
Condition & Dose & P-value & Example\\
\hline
\multicolumn{4}{|c|}{Decreased \textit{Interphase} distances}\\
\hline
BPA,9 &$50\mu M$ &0.0001 & \\
MeHg,9 & $1\mu M$&	0.0048&\\
PCB,10 & $100\mu M$ &0.0059&\\
\hline
\multicolumn{4}{|c|}{Increased \textit{Frozen} distances}\\
\hline
BPA,9 &$50\mu M$ &0.0001 & Supp. movie 2\\
PCB,10 & $100\mu M$ &0.0003&Supp. movie 3\\%1212 w 37
MeHg,9 & $1\mu M$&	0.0054&\\
Endo,10 &$100\mu M$ &0.0097&\\
PCB,9 & $50\mu M$ &0.048&\\
\hline
\multicolumn{4}{|c|}{Increased \textit{Micronucleated} distances}\\
\hline
PCB,1 & $0.1 nM$ & 0.015 & Supp. movie 4 \\ %1212 w 48, others nothing
\textit{Rien} & 0 & 0.072 & Supp. movie 5\\ %2011 w 82, 2712 w87
\hline
\end{tabular}

\end{table} 		
\begin{figure}
\caption{Interphase (up) and frozen(down) distances. Colors are black for control wells, yellow to red for xenobiotics ranked by increased dose, and magenta for TGF-$\beta$1. B: BPA, D:DMSO, E: Endo, M: MeHg, N: Nonane, P:PCB, R: nothing, T(red):TCDD, T(magenta): TGF-$\beta$1}
\centering
\label{interphase}
\includegraphics[scale=0.4]{figures/interphase.png}
\includegraphics[scale=0.4]{figures/frozen.png}
\end{figure}

\section{Discussion}

A workflow is established, which is accompanied by a Web interface, to
enable the analysis of time-lapse xenobiotic screening
experiments. However, on the panel of xenobiotics and doses which were
chosen for our set of experiments, it was not possible to detect
subtler effects than a toxic effect at the highest doses.
This is
probably due to a combination of the following reasons: we observed a
relatively high level of experimental noise, even in negative
controls, which might be due to the biological variability of the used
cell line, which showed many aberrant divisions, to experimental noise due to microscope intensity
variations and low intensity of the fluorescence signal and the sensitivity of our
trajectory measurements. Even though our results are not conclusive on
this project, we feel that it would be premature to conclude that the screening approach
is not suited for Environmental predictive Toxicology. 

As a general remark, it should not be forgotten that it is very likely that a xenobiotic screen will never be as visually extraordinary as a siRNA or drug screen. Most xenobiotics are not - at sub-toxic doses - targeted at one single vital cellular process, as opposed to some siRNAs (especially those which were enlighted by the Mitocheck project, whose goal was to study cell division). Hence, they are less specific, and their effects can be slower. Nevertheless, previous results had let one hope that, e.g., significant cell division defects could be obtained following TCDD exposure (\cite{pmid20089886},~\cite{pmid18640100},~\cite{pmid11479202}).

\paragraph{Dose choices\\}
Ten doses were chosen for each xenobiotic, spanning from four to six orders of magnitude. Dose ranges were selected in order to be non-toxic, as well as to include real human exposure dose (following a literature survey, see appendix~\ref{literature_review}). This may not have been the surest way to detect an effect. Indeed, depending on their mechanisms of action, xenobiotics are going to be active in a smaller range, which we could easily have missed in the current setting.

In the future, dose choices could be improved in two ways. First of all, although human exposure doses are extremely relevant, they may be too small for an exploratory screen, where effects should be observed for the screen to be an efficient proof of concept. Rather, if previous similar studies exist, the doses which they find to be effective on cell division or cell motility should be used. However, given the novelty of the current approach in Environmental Toxicology, such previous similar studies are extremely rare. Previous studies using different cell lines or different measures for evaluating the same process should be considered with caution\footnote{As an example, although there exists several studies about measuring the impact of TCDD exposure on MCF-7 cell motility (e.g.~\cite{pmid16619036},~\cite{pmid22266097}), it is not clear at all that the same parameters are measured by MotIW (single cell motility versus cell population migration).}.

Hence a second and more robust way to improve dose choices would be to perform pre-screening (which also enables quality control setting and instrument and reagent validation - personal communications, Dr Wolfgang Huber and Dr Beate Neumann, EMBL, Heidelberg, Germany). The simplest way is to look for the lowest slightly toxic dose starting from $10$ to $50 \mu M$, and further dilute it of a factor 2 or 3 (rather than 10). 

This is precisely the approach which was chosen by~\cite{pmid24691702}. Willing to define a framework for developmental toxicity test battery, they had to select compounds for performing a proof of concept. They do note that human plasma concentrations are relevant when it comes to environmental contaminants such as PCB153. However given that they are around 1nM for the latter example, they also search for evidence of developmental toxicity in the literature, and do use higher concentrations while pre-screening and screening it. More elaborate approaches to pre-screening are also possible. As an example,~\cite{pmid24997295} used both cell viability assays and measures of cell area, mitochondrial activity and percentage of cells below 2N to define a "zone of interest" for further investigation.

In summary, dose choices should be chosen according to pratical reasons (significant effect observed with local experimental parameters) instead of theoretical reasons (human exposure). Another parameter which should be set in this way is the time-lapse between cell exposure and screen start.

\paragraph{Cell line choice\\}
A second parameter of importance is the cell line. Although MCF-7 cells are often chosen as a model for breast cancer, they exhibit a significant basal heterogeneity with regard to oestrogen receptor status and cell area~\cite{pmid11153613}. Screening is already subject to a certain amount of variance in its results, due to cell sensitivity to experimental parameters such as cell local confluence level~\cite{pmid19710653} or passage number, and gene expression stochasticity (\cite{pmid12183631},~\cite{pmid18957198}). For a proof of concept, it may therefore be relevant to choose a cell line which is inherently as homogeneous as possible.

In the current case, MCF-7 cells were genetically modified for incorporating H2B-mCherry and myrPalm-GFP. It appears that the chosen clone exhibits a high basal level of micronuclei. In the future, genetically modified clones should be checked both for a normal response to TCDD exposure and normal cell division.


%Ideas to discuss: \\
%
%1. five xb, 10 doses but maybe pre-select the doses and exposure time first and then study deeper on a smaller concentration range? \cite{pmid24997295} 

%2. motility :  interesting to the extent that the conditions were not detected as toxic following cytotoxicity assays. However visually it looks like phototoxicity. Possible synergy between toxicity and phototox
%
%3. high level of micronucleated nuclei at base-leve => possible pbl with the cell line. Probably made the dataset noisy on a phenotypic level, hence nothing pops out.